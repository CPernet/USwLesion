# Brain Tumour Validation Scheme

USwLesion validation. The algorithm segments tissues using spatial priors in template (MNI) space. What is required is to provide a template with tissue classes and a mask of the lesion that will be moved into MNI space, first using an affine transform.

## BRAT

The data we are using has been acquired from the Multimodal Brain Tumour Image Segmentation Benchmark (BRATS) challenge. This venture was organised in 2012/2013 to assess and compare state-of-the-art automated brain tumour segmentation methods, and involved application of twenty algorithms to a dataset of low- and high-grade glioma patients (with the tumours manually delineated by up to four human expert raters), as well as 65 simulated synthetic scans. The study indicated that different algorithms were particularly successful for specific tumour sub-regions, with the associated errors being comparable to human inter-rater variability. No single algorithm performed best for all sub-regions simultaneously, and fusing different algorithms was found to improve performance significantly.

## Creation of masks and comparison to ground truth

For each of the 30 patients, we create two rough masks of the tumour using the 3D fill tool in MRICROn (one is of regular size and the second overshoots). These are visually checked against the ground truth, with overlap metrics then computed to get an idea of overlap and distribution in the quality of the masks as well as volumes of tumours for masks and ground truth.

*_Overlap Metrics_*:

The Modified Jaccard Index (mJ) is defined as the size of the intersection of the masks divided by the size of their union.

The Dice coefficient (Dice) is the most commonly used metric in validating medical volume segmentations, and measures the spatial overlap between two binary images. It is a semimetric version of the Jaccard index, defined as twice the intersection of the masks divided by their sum. Dice coefficient values range from 0 (no overlap) to 1 (exact overlap).

The Mean Hausdorff distance (mHd) is a mathematical construct to measure the 'closeness' of two sets of points that are subsets of a metric space, i.e. a surface distance measure. Here, mHd measures the similarity between the contour of the masks.

To understand the following two overlap metrics, it is necessary to define a number of variables associated with the images: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). TP refers to the number of voxels correctly segmented as the lesion by ground truth and the algorithm; FP refers to voxels classified as lesion by the algorithm but not the ground truth, therefore indicating voxels falsely segmented as lesion by the algorithm; TN refers to voxels not classified as lesion by either the ground truth or the algorithm, therefore indicating voxels correctly assigned as background; FN refers to voxels classified as lesion in the ground truth but not by the algorithm, therefore indicating voxels incorrectly assigned as background.

The Matthews correlation coefficient (overlap.mcc) analyses the lesion mask and ground truth as two sets, utilising TP and TN to calculate a correlation coefficient that ranges from -1 (complete disagreement) to 1 (complete agreement).

Cohen's Kappa coefficient (overlap.CK) is a metric that compares observed accuracy with expected accuracy (random chance). It is calculated by taking the agreement expected by chance away from the observed agreement and dividing by the maximum possible agreement.

### why using multiple metrics?

No single evaluation metric is consistently the best for validating medical image segmentation algorithms: each will be sensitive to at least one type of segmentation error, e.g. size, location, shape.

Size-based metrics account only for difference in size between the segmentation and ground truth.
Overlap-based methods account only for the number of correctly classified or misclassified voxels without taking into account their spatial distribution.
Distance-based metrics take into account only the distance from a point on one boundary to the other boundary, without taking into account the size of the regions involved. 

There is therefore no agreed framework for evaluating the results of segmentation.

## Running segmentation routine

The segmentation routine is called in order to obtain the new lesion masks:
- We start with two lesion masks of each patient, either smaller than ground truth or larger.
- the segmentation routine runs with a variation of input parameter combinations: number of Gaussians (2, 3 or non parametric). the number of tissues that can be classified as 'affected' (i.e. GM+WM or GM+WM+CSF)
- from the mask outputs, different thresholding of the probabilistic lesion mask are performed: similarity to the ground truth is computed with binary masks defined as 1. probability of lesion being higher than 50%, 2. higher than 99%, 3. higher than the probability of any other tissue, 4. higher than the probability of each of the other tissues, 5. higher than the probability of the other tissues combined.

This means that for each patient there will be 60 different lesion masks generated following application of the segmentation routine (12 parameter combinations multiplied by 5 thresholding methods).

## Statistically testing which combination of parameters/thresholding method gives the best match to ground truth

The purpose of running stats on the data is to identify which of the 60 possible parameter combinations applied during segmentation generates a lesion mask that is best-matched to the ground truth.

The independant variables are the mask size, the number of gaussians for the lesion, the tissue model, and the thresholding method, leading to 60 possibilities per subject. The dependant variables are the 5 measures of similarity (change from pre- to post-segmentation; mJ, mHd, mcc, kappa, Dice).

### Results Classification

Ranking

Clustering

## Variance partitioning
